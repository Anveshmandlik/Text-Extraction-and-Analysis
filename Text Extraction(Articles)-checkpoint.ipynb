{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83332d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbb261ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "   \n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4600c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the Title and the main text\n",
    "def extract_article_text(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        for element in soup.find_all(['script', 'style', 'header', 'footer']):\n",
    "            element.extract()\n",
    "\n",
    "        # extract the article title\n",
    "        title = soup.title.string.strip() if soup.title else ''\n",
    "\n",
    "        # article text\n",
    "        article_text = \"\"\n",
    "        for paragraph in soup.find_all('p'):\n",
    "            article_text += paragraph.get_text() + '\\n'\n",
    "\n",
    "        # Clean the extracted text\n",
    "        title = clean_text(title)\n",
    "        article_text = clean_text(article_text)\n",
    "\n",
    "        return title, article_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {url}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "963e9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of URL_IDs and URLs\n",
    "url_data = {\n",
    "    123: \"https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-3-2/\",\n",
    "    321: \"https://insights.blackcoffer.com/rise-of-e-health-and-its-impact-on-humans-by-the-year-2030/\",\n",
    "    2345: \"https://insights.blackcoffer.com/rise-of-e-health-and-its-imapct-on-humans-by-the-year-2030-2/\",\n",
    "    4321: \"https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-2/\",\n",
    "    432: \"https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-2-2/\",\n",
    "    2893.8: \"https://insights.blackcoffer.com/rise-of-chatbots-and-its-impact-on-customer-support-by-the-year-2040/\",\n",
    "    3355.6: \"https://insights.blackcoffer.com/rise-of-e-health-and-its-imapct-on-humans-by-the-year-2030/\",\n",
    "    3817.4: \"https://insights.blackcoffer.com/how-does-marketing-influence-businesses-and-consumers/\",\n",
    "    4279.2: \"https://insights.blackcoffer.com/how-advertisement-increase-your-market-value/\",\n",
    "    4741: \"https://insights.blackcoffer.com/negative-effects-of-marketing-on-society/\",\n",
    "    5202.8: \"https://insights.blackcoffer.com/how-advertisement-marketing-affects-business/\",\n",
    "    5664.6: \"https://insights.blackcoffer.com/rising-it-cities-will-impact-the-economy-environment-infrastructure-and-city-life-by-the-year-2035/\",\n",
    "    6126.4: \"https://insights.blackcoffer.com/rise-of-ott-platform-and-its-impact-on-entertainment-industry-by-the-year-2030/\",\n",
    "    6588.2: \"https://insights.blackcoffer.com/rise-of-electric-vehicles-and-its-impact-on-livelihood-by-2040/\",\n",
    "    7050: \"https://insights.blackcoffer.com/rise-of-electric-vehicle-and-its-impact-on-livelihood-by-the-year-2040/\",\n",
    "    7511.8: \"https://insights.blackcoffer.com/oil-prices-by-the-year-2040-and-how-it-will-impact-the-world-economy/\",\n",
    "    7973.6:\"https://insights.blackcoffer.com/an-outlook-of-healthcare-by-the-year-2040-and-how-it-will-impact-human-lives/\",\n",
    "8435.4:\"https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/\",\n",
    "8897.2:\"https://insights.blackcoffer.com/what-if-the-creation-is-taking-over-the-creator/\",\n",
    "9359:\"https://insights.blackcoffer.com/what-jobs-will-robots-take-from-humans-in-the-future/\",\n",
    "9820.8:\"https://insights.blackcoffer.com/will-machine-replace-the-human-in-the-future-of-work/\",\n",
    "10282.6:\"https://insights.blackcoffer.com/will-ai-replace-us-or-work-with-us/\",\n",
    "10744.4:\"https://insights.blackcoffer.com/man-and-machines-together-machines-are-more-diligent-than-humans-blackcoffe/\",\n",
    "11206.2:\"https://insights.blackcoffer.com/in-future-or-in-upcoming-years-humans-and-machines-are-going-to-work-together-in-every-field-of-work/\",\n",
    "11668:\"https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\",\n",
    "12129.8:\"https://insights.blackcoffer.com/how-machine-learning-will-affect-your-business/\",\n",
    "12591.6:\"https://insights.blackcoffer.com/deep-learning-impact-on-areas-of-e-learning/\",\n",
    "13053.4:\"https://insights.blackcoffer.com/how-to-protect-future-data-and-its-privacy-blackcoffer/\",\n",
    "13515.2:\"https://insights.blackcoffer.com/how-machines-ai-automations-and-robo-human-are-effective-in-finance-and-banking/\",\n",
    "13977:\"https://insights.blackcoffer.com/ai-human-robotics-machine-future-planet-blackcoffer-thinking-jobs-workplace/\",\n",
    "14438.8:\"https://insights.blackcoffer.com/how-ai-will-change-the-world-blackcoffer/\",\n",
    "14900.6:\"https://insights.blackcoffer.com/future-of-work-how-ai-has-entered-the-workplace/\",\n",
    "15362.4:\"https://insights.blackcoffer.com/ai-tool-alexa-google-assistant-finance-banking-tool-future/\",\n",
    "15824.2:\"https://insights.blackcoffer.com/ai-healthcare-revolution-ml-technology-algorithm-google-analytics-industrialrevolution/\",\n",
    "16286:\"https://insights.blackcoffer.com/all-you-need-to-know-about-online-marketing/\",\n",
    "16747.8:\"https://insights.blackcoffer.com/evolution-of-advertising-industry/\",\n",
    "17209.6:\"https://insights.blackcoffer.com/how-data-analytics-can-help-your-business-respond-to-the-impact-of-covid-19/\",\n",
    "17671.4:\"https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\",\n",
    "18133.2:\"https://insights.blackcoffer.com/environmental-impact-of-the-covid-19-pandemic-lesson-for-the-future/\",\n",
    "18595:\"https://insights.blackcoffer.com/how-data-analytics-and-ai-are-used-to-halt-the-covid-19-pandemic/\",\n",
    "19056.8:\"https://insights.blackcoffer.com/difference-between-artificial-intelligence-machine-learning-statistics-and-data-mining/\",\n",
    "19518.6:\"https://insights.blackcoffer.com/how-python-became-the-first-choice-for-data-science/\",\n",
    "19980.4:\"https://insights.blackcoffer.com/how-google-fit-measure-heart-and-respiratory-rates-using-a-phone/\",\n",
    "20442.2:\"https://insights.blackcoffer.com/what-is-the-future-of-mobile-apps/\",\n",
    "20904:\"https://insights.blackcoffer.com/impact-of-ai-in-health-and-medicine/\",\n",
    "21365.8:\"https://insights.blackcoffer.com/telemedicine-what-patients-like-and-dislike-about-it/\",\n",
    "21827.6:\"https://insights.blackcoffer.com/how-we-forecast-future-technologies/\",\n",
    "22289.4:\"https://insights.blackcoffer.com/can-robots-tackle-late-life-loneliness/\",\n",
    "22751.2:\"https://insights.blackcoffer.com/embedding-care-robots-into-society-socio-technical-considerations/\",\n",
    "23213:\"https://insights.blackcoffer.com/management-challenges-for-future-digitalization-of-healthcare-services/\",\n",
    "23674.8:\"https://insights.blackcoffer.com/are-we-any-closer-to-preventing-a-nuclear-holocaust/\",\n",
    "24136.6:\"https://insights.blackcoffer.com/will-technology-eliminate-the-need-for-animal-testing-in-drug-development/\",\n",
    "24598.4:\"https://insights.blackcoffer.com/will-we-ever-understand-the-nature-of-consciousness/\",\n",
    "25060.2:\"https://insights.blackcoffer.com/will-we-ever-colonize-outer-space/\",\n",
    "25522:\"https://insights.blackcoffer.com/what-is-the-chance-homo-sapiens-will-survive-for-the-next-500-years/\",\n",
    "25983.8:\"https://insights.blackcoffer.com/why-does-your-business-need-a-chatbot/\",\n",
    "26445.6:\"https://insights.blackcoffer.com/how-you-lead-a-project-or-a-team-without-any-technical-expertise/\",\n",
    "26907.4:\"https://insights.blackcoffer.com/can-you-be-great-leader-without-technical-expertise/\",\n",
    "27369.2:\"https://insights.blackcoffer.com/how-does-artificial-intelligence-affect-the-environment/\",\n",
    "27831:\"https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes-2/\",\n",
    "28292.8:\"https://insights.blackcoffer.com/is-perfection-the-greatest-enemy-of-productivity/\",\n",
    "28754.6:\"https://insights.blackcoffer.com/global-financial-crisis-2008-causes-effects-and-its-solution/\",\n",
    "29216.4:\"https://insights.blackcoffer.com/gender-diversity-and-equality-in-the-tech-industry/\",\n",
    "29678.2:\"https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes/\",\n",
    "30140:\"https://insights.blackcoffer.com/how-small-business-can-survive-the-coronavirus-crisis/\",\n",
    "30601.8:\"https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors-and-food-stalls/\",\n",
    "31063.6:\"https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors/\",\n",
    "31525.4:\"https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-tourism-aviation-industries/\",\n",
    "31987.2:\"https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-sports-events-around-the-world/\",\n",
    "32449:\"https://insights.blackcoffer.com/changing-landscape-and-emerging-trends-in-the-indian-it-ites-industry/\",\n",
    "32910.8:\"https://insights.blackcoffer.com/online-gaming-adolescent-online-gaming-effects-demotivated-depression-musculoskeletal-and-psychosomatic-symptoms/\",\n",
    "33372.6:\"https://insights.blackcoffer.com/human-rights-outlook/\",\n",
    "33834.4:\"https://insights.blackcoffer.com/how-voice-search-makes-your-business-a-successful-business/\",\n",
    "34296.2:\"https://insights.blackcoffer.com/how-the-covid-19-crisis-is-redefining-jobs-and-services/\",\n",
    "34758:\"https://insights.blackcoffer.com/how-to-increase-social-media-engagement-for-marketers/\",\n",
    "35219.8:\"https://insights.blackcoffer.com/impacts-of-covid-19-on-streets-sides-food-stalls/\",\n",
    "35681.6:\"https://insights.blackcoffer.com/coronavirus-impact-on-energy-markets-2/\",\n",
    "36143.4:\"https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-5/\",\n",
    "36605.2:\"https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-4/\",\n",
    "37067:\"https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-2/\",\n",
    "37528.8:\"https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-3/\",\n",
    "37990.6:\"https://insights.blackcoffer.com/travel-and-tourism-outlook/\",\n",
    "38452.4:\"https://insights.blackcoffer.com/gaming-disorder-and-effects-of-gaming-on-health/\",\n",
    "38914.2:\"https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation/\",\n",
    "39376:\"https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation-2/\",\n",
    "39837.8:\"https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-office-space-and-co-working-industries/\",\n",
    "40299.6:\"https://insights.blackcoffer.com/contribution-of-handicrafts-visual-arts-literature-in-the-indian-economy/\",\n",
    "40761.4:\"https://insights.blackcoffer.com/how-covid-19-is-impacting-payment-preferences/\",\n",
    "41223.2:\"https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-2/\",\n",
    "41685:\"https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis/\",\n",
    "42146.8:\"https://insights.blackcoffer.com/covid-19-how-have-countries-been-responding/\",\n",
    "42608.6:\"https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-2/\",\n",
    "43070.4:\"https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-3/\",\n",
    "43532.2:\"https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-3/\",\n",
    "43994:\"https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work/\",\n",
    "44455.8:\"https://insights.blackcoffer.com/covid-19-how-have-countries-been-responding-2/\",\n",
    "44917.6:\"https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-4/\",\n",
    "45379.4:\"https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-2/\",\n",
    "45841.2:\"https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-3/\",\n",
    "46303:\"https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-4/\",\n",
    "46764.8:\"https://insights.blackcoffer.com/why-scams-like-nirav-modi-happen-with-indian-banks/\",\n",
    "47226.6:\"https://insights.blackcoffer.com/impact-of-covid-19-on-the-global-economy/\",\n",
    "47688.4:\"https://insights.blackcoffer.com/impact-of-covid-19coronavirus-on-the-indian-economy-2/\",\n",
    "48150.2:\"https://insights.blackcoffer.com/impact-of-covid-19-on-the-global-economy-2/\",\n",
    "48612:\"https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-indian-economy-3/\",\n",
    "49073.8:\"https://insights.blackcoffer.com/should-celebrities-be-allowed-to-join-politics/\",\n",
    "49535.6:\"https://insights.blackcoffer.com/how-prepared-is-india-to-tackle-a-possible-covid-19-outbreak/\",\n",
    "49997.4:\"https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work/\",\n",
    "50459.2:\"https://insights.blackcoffer.com/controversy-as-a-marketing-strategy/\",\n",
    "50921:\"https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry/\",\n",
    "51382.8:\"https://insights.blackcoffer.com/coronavirus-impact-on-energy-markets/\",\n",
    "51844.6:\"https://insights.blackcoffer.com/what-are-the-key-policies-that-will-mitigate-the-impacts-of-covid-19-on-the-world-of-work/\",\n",
    "52306.4:\"https://insights.blackcoffer.com/marketing-drives-results-with-a-focus-on-problems/\",\n",
    "52768.2:\"https://insights.blackcoffer.com/continued-demand-for-sustainability/\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8826bc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output\\123.txt\n",
      "Saved output\\321.txt\n",
      "Saved output\\2345.txt\n",
      "Saved output\\4321.txt\n",
      "Saved output\\432.txt\n",
      "Saved output\\2893.8.txt\n",
      "Saved output\\3355.6.txt\n",
      "Saved output\\3817.4.txt\n",
      "Saved output\\4279.2.txt\n",
      "Saved output\\4741.txt\n",
      "Saved output\\5202.8.txt\n",
      "Saved output\\5664.6.txt\n",
      "Saved output\\6126.4.txt\n",
      "Saved output\\6588.2.txt\n",
      "Saved output\\7050.txt\n",
      "Saved output\\7511.8.txt\n",
      "Saved output\\7973.6.txt\n",
      "Saved output\\8435.4.txt\n",
      "Saved output\\8897.2.txt\n",
      "Saved output\\9359.txt\n",
      "Saved output\\9820.8.txt\n",
      "Saved output\\10282.6.txt\n",
      "Saved output\\10744.4.txt\n",
      "Saved output\\11206.2.txt\n",
      "Saved output\\11668.txt\n",
      "Saved output\\12129.8.txt\n",
      "Saved output\\12591.6.txt\n",
      "Saved output\\13053.4.txt\n",
      "Saved output\\13515.2.txt\n",
      "Saved output\\13977.txt\n",
      "Saved output\\14438.8.txt\n",
      "Saved output\\14900.6.txt\n",
      "Saved output\\15362.4.txt\n",
      "Saved output\\15824.2.txt\n",
      "Saved output\\16286.txt\n",
      "Saved output\\16747.8.txt\n",
      "Saved output\\17209.6.txt\n",
      "Saved output\\17671.4.txt\n",
      "Saved output\\18133.2.txt\n",
      "Saved output\\18595.txt\n",
      "Saved output\\19056.8.txt\n",
      "Saved output\\19518.6.txt\n",
      "Saved output\\19980.4.txt\n",
      "Saved output\\20442.2.txt\n",
      "Saved output\\20904.txt\n",
      "Saved output\\21365.8.txt\n",
      "Saved output\\21827.6.txt\n",
      "Saved output\\22289.4.txt\n",
      "Saved output\\22751.2.txt\n",
      "Saved output\\23213.txt\n",
      "Saved output\\23674.8.txt\n",
      "Saved output\\24136.6.txt\n",
      "Saved output\\24598.4.txt\n",
      "Saved output\\25060.2.txt\n",
      "Saved output\\25522.txt\n",
      "Saved output\\25983.8.txt\n",
      "Saved output\\26445.6.txt\n",
      "Saved output\\26907.4.txt\n",
      "Saved output\\27369.2.txt\n",
      "Saved output\\27831.txt\n",
      "Saved output\\28292.8.txt\n",
      "Saved output\\28754.6.txt\n",
      "Saved output\\29216.4.txt\n",
      "Saved output\\29678.2.txt\n",
      "Saved output\\30140.txt\n",
      "Saved output\\30601.8.txt\n",
      "Saved output\\31063.6.txt\n",
      "Saved output\\31525.4.txt\n",
      "Saved output\\31987.2.txt\n",
      "Saved output\\32449.txt\n",
      "Saved output\\32910.8.txt\n",
      "Saved output\\33372.6.txt\n",
      "Saved output\\33834.4.txt\n",
      "Saved output\\34296.2.txt\n",
      "Saved output\\34758.txt\n",
      "Saved output\\35219.8.txt\n",
      "Saved output\\35681.6.txt\n",
      "Saved output\\36143.4.txt\n",
      "Saved output\\36605.2.txt\n",
      "Saved output\\37067.txt\n",
      "Saved output\\37528.8.txt\n",
      "Saved output\\37990.6.txt\n",
      "Saved output\\38452.4.txt\n",
      "Saved output\\38914.2.txt\n",
      "Saved output\\39376.txt\n",
      "Saved output\\39837.8.txt\n",
      "Saved output\\40299.6.txt\n",
      "Saved output\\40761.4.txt\n",
      "Saved output\\41223.2.txt\n",
      "Saved output\\41685.txt\n",
      "Saved output\\42146.8.txt\n",
      "Saved output\\42608.6.txt\n",
      "Saved output\\43070.4.txt\n",
      "Saved output\\43532.2.txt\n",
      "Saved output\\43994.txt\n",
      "Saved output\\44455.8.txt\n",
      "Saved output\\44917.6.txt\n",
      "Saved output\\45379.4.txt\n",
      "Saved output\\45841.2.txt\n",
      "Saved output\\46303.txt\n",
      "Saved output\\46764.8.txt\n",
      "Saved output\\47226.6.txt\n",
      "Saved output\\47688.4.txt\n",
      "Saved output\\48150.2.txt\n",
      "Saved output\\48612.txt\n",
      "Saved output\\49073.8.txt\n",
      "Saved output\\49535.6.txt\n",
      "Saved output\\49997.4.txt\n",
      "Saved output\\50459.2.txt\n",
      "Saved output\\50921.txt\n",
      "Saved output\\51382.8.txt\n",
      "Saved output\\51844.6.txt\n",
      "Saved output\\52306.4.txt\n",
      "Saved output\\52768.2.txt\n",
      "Extraction and saving completed.\n"
     ]
    }
   ],
   "source": [
    "# output directory\n",
    "output_directory = \"output\"\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "\n",
    "for url_id, url in url_data.items():\n",
    "    # Extract article text from the URL\n",
    "    title, article_text = extract_article_text(url)\n",
    "    \n",
    "    if title and article_text:\n",
    "        # Create the file name using URL_ID\n",
    "        filename = os.path.join(output_directory, f\"{url_id}.txt\")\n",
    "        \n",
    "        # Saving the extracted article to a text file\n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            file.write(title + '\\n\\n')\n",
    "            file.write(article_text)\n",
    "        print(f\"Saved {filename}\")\n",
    "\n",
    "print(\"Extraction and saving completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d87300e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textstat\n",
      "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
      "     ------------------------------------ 105.1/105.1 kB 608.2 kB/s eta 0:00:00\n",
      "Collecting pyphen\n",
      "  Downloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 728.7 kB/s eta 0:00:00\n",
      "Installing collected packages: pyphen, textstat\n",
      "Successfully installed pyphen-0.14.0 textstat-0.7.3\n"
     ]
    }
   ],
   "source": [
    "!pip install textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6692c1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n",
      "[nltk_data] Error loading vader_lexicon: <urlopen error [WinError\n",
      "[nltk_data]     10060] A connection attempt failed because the\n",
      "[nltk_data]     connected party did not properly respond after a\n",
      "[nltk_data]     period of time, or established connection failed\n",
      "[nltk_data]     because connected host has failed to respond>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis results saved to sentiment_analysis_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "stop_words_files = [\n",
    "    \"StopWords_Auditor.txt\",\n",
    "    \"StopWords_Currencies.txt\",\n",
    "    \"StopWords_DatesandNumbers.txt\",\n",
    "    \"StopWords_Generic.txt\",\n",
    "    \"StopWords_GenericLong.txt\",\n",
    "    \"StopWords_Geographic.txt\",\n",
    "    \"StopWords_Names.txt\"\n",
    "]\n",
    "\n",
    "stop_words = set()\n",
    "for stop_words_file in stop_words_files:\n",
    "    with open(os.path.join(\"StopWords\", stop_words_file), 'r', encoding='latin-1') as file:\n",
    "        stop_words.update(file.read().splitlines())\n",
    "\n",
    "# ...\n",
    "\n",
    "# Initialize SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# list to store sentiment analysis results\n",
    "sentiment_results = []\n",
    "\n",
    "output_directory = \"output\"\n",
    "\n",
    "\n",
    "for filename in os.listdir(output_directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        filepath = os.path.join(output_directory, filename)\n",
    "\n",
    "       \n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # Tokenize the text\n",
    "        words = word_tokenize(text)\n",
    "\n",
    "        # Remove stop words\n",
    "        words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "        # sentiment analysis\n",
    "        sentiment = sia.polarity_scores(text)\n",
    "\n",
    "        positive_score = sentiment['pos']\n",
    "        negative_score = sentiment['neg']\n",
    "        polarity_score = (positive_score - negative_score) / (positive_score + negative_score + 0.000001)\n",
    "        subjectivity_score = (positive_score + negative_score) / (len(words) + 0.000001)\n",
    "\n",
    "        # Store the sentiment analysis results in a list\n",
    "        sentiment_results.append({\n",
    "            'File Name': filename,\n",
    "            'Positive Score': positive_score,\n",
    "            'Negative Score': negative_score,\n",
    "            'Polarity Score': polarity_score,\n",
    "            'Subjectivity Score': subjectivity_score\n",
    "        })\n",
    "\n",
    "# Creating a DataFrame from the sentiment results list\n",
    "df = pd.DataFrame(sentiment_results)\n",
    "\n",
    "# Saving the DataFrame to an Excel file\n",
    "output_file = \"sentiment_analysis_results.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Sentiment analysis results saved to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e6bc16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n",
      "[nltk_data] Error loading vader_lexicon: <urlopen error [WinError\n",
      "[nltk_data]     10060] A connection attempt failed because the\n",
      "[nltk_data]     connected party did not properly respond after a\n",
      "[nltk_data]     period of time, or established connection failed\n",
      "[nltk_data]     because connected host has failed to respond>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readability analysis results appended to sentiment_analysis_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "stop_words_files = [\n",
    "    \"StopWords_Auditor.txt\",\n",
    "    \"StopWords_Currencies.txt\",\n",
    "    \"StopWords_DatesandNumbers.txt\",\n",
    "    \"StopWords_Generic.txt\",\n",
    "    \"StopWords_GenericLong.txt\",\n",
    "    \"StopWords_Geographic.txt\",\n",
    "    \"StopWords_Names.txt\"\n",
    "]\n",
    "\n",
    "stop_words = set()\n",
    "for stop_words_file in stop_words_files:\n",
    "    with open(os.path.join(\"StopWords\", stop_words_file), 'r', encoding='latin-1') as file:\n",
    "        stop_words.update(file.read().splitlines())\n",
    "\n",
    "# Initialize SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Create a list to store sentiment analysis and readability results\n",
    "results = []\n",
    "\n",
    "\n",
    "output_directory = \"output\"\n",
    "\n",
    "\n",
    "for filename in os.listdir(output_directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        filepath = os.path.join(output_directory, filename)\n",
    "\n",
    "     \n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # Tokenize the text\n",
    "        words = word_tokenize(text)\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        # Remove stop words and punctuation\n",
    "        cleaned_words = [word.lower() for word in words if word.lower() not in stop_words and word.isalpha()]\n",
    "\n",
    "        # Calculate readability metrics\n",
    "        average_sentence_length = len(words) / len(sentences)\n",
    "        complex_word_count = sum(1 for word in cleaned_words if len(word) > 2)\n",
    "        percentage_complex_words = complex_word_count / len(cleaned_words)\n",
    "        fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n",
    "\n",
    "        # Calculate additional readability metrics\n",
    "        average_word_count_per_sentence = len(cleaned_words) / len(sentences)\n",
    "\n",
    "        # Count syllables per word\n",
    "        def count_syllables(word):\n",
    "            # Count the number of vowels in the word (excluding certain endings)\n",
    "            word = re.sub(r'ed$', '', word)\n",
    "            word = re.sub(r'es$', '', word)\n",
    "            vowels = \"aeiouyAEIOUY\"\n",
    "            syllables = 0\n",
    "            prev_char = ''\n",
    "            for char in word:\n",
    "                if char in vowels and prev_char not in vowels:\n",
    "                    syllables += 1\n",
    "                prev_char = char\n",
    "            # Adjust for words with no vowels (e.g., \"cry\")\n",
    "            if syllables == 0:\n",
    "                syllables = 1\n",
    "            return syllables\n",
    "\n",
    "        syllable_count_per_word = sum(count_syllables(word) for word in cleaned_words)\n",
    "\n",
    "        # Count personal pronouns\n",
    "        personal_pronoun_count = len(re.findall(r'\\b(?:I|we|my|ours|us)\\b', text, re.IGNORECASE))\n",
    "\n",
    "        # Calculate average word length\n",
    "        average_word_length = sum(len(word) for word in cleaned_words) / len(cleaned_words)\n",
    "\n",
    "        # Append results to the list\n",
    "        results.append({\n",
    "            'File Name': filename,\n",
    "            'Average Sentence Length': average_sentence_length,\n",
    "            'Complex Word Count': complex_word_count,\n",
    "            'Percentage of Complex Words': percentage_complex_words,\n",
    "            'Fog Index': fog_index,\n",
    "            'Average Number of Words Per Sentence': average_word_count_per_sentence,\n",
    "            'Syllable Count Per Word': syllable_count_per_word,\n",
    "            'Personal Pronoun Count': personal_pronoun_count,\n",
    "            'Average Word Length': average_word_length\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "existing_df = pd.read_excel(\"sentiment_analysis_results.xlsx\")\n",
    "\n",
    "# Merge the sentiment analysis and readability results on 'File Name'\n",
    "merged_df = existing_df.merge(df, on='File Name')\n",
    "\n",
    "# Save the merged DataFrame to an Excel file\n",
    "merged_df.to_excel(\"sentiment_analysis_results.xlsx\", index=False)\n",
    "\n",
    "print(f\"Readability analysis results appended to sentiment_analysis_results.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
